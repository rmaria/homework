{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, Input,MaxPool2D, Reshape,Activation,Flatten, Dense, Permute\n",
    "from keras.models import Model, Sequential\n",
    "import tensorflow as tf\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "import numpy as np\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Kao_Onet( weight_path = 'models/48net.h5'):\n",
    "    input = Input(shape = [48,48,3])\n",
    "    x = Conv2D(32, (3, 3), strides=1, padding='valid', name='conv1')(input)\n",
    "    x = PReLU(shared_axes=[1,2],name='prelu1')(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(shared_axes=[1,2],name='prelu2')(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2)(x)\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(shared_axes=[1,2],name='prelu3')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Conv2D(128, (2, 2), strides=1, padding='valid', name='conv4')(x)\n",
    "    x = PReLU(shared_axes=[1,2],name='prelu4')(x)\n",
    "    x = Permute((3,2,1))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(256, name='conv5') (x)\n",
    "    x = PReLU(name='prelu5')(x)\n",
    "\n",
    "    classifier = Dense(2, activation='softmax',name='conv6-1')(x)\n",
    "    bbox_regress = Dense(4,name='conv6-2')(x)\n",
    "    landmark_regress = Dense(10,name='conv6-3')(x)\n",
    "    model = Model([input], [classifier, bbox_regress, landmark_regress])\n",
    "    model.load_weights(weight_path, by_name=True)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Kao_Rnet (weight_path = 'models/24net.h5'):\n",
    "    input = Input(shape=[24, 24, 3])  # change this shape to [None,None,3] to enable arbitraty shape input\n",
    "    x = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu1')(x)\n",
    "    x = MaxPool2D(pool_size=3,strides=2, padding='same')(x)\n",
    "\n",
    "    x = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu2')(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = Conv2D(64, (2, 2), strides=1, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu3')(x)\n",
    "    x = Permute((3, 2, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, name='conv4')(x)\n",
    "    x = PReLU( name='prelu4')(x)\n",
    "    classifier = Dense(2, activation='softmax', name='conv5-1')(x)\n",
    "    bbox_regress = Dense(4, name='conv5-2')(x)\n",
    "    model = Model([input], [classifier, bbox_regress])\n",
    "    model.load_weights(weight_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_Kao_Pnet( weight_path = 'models/12net.h5'):\n",
    "    input = Input(shape=[None, None, 3])\n",
    "    x = Conv2D(10, (3, 3), strides=1, padding='valid', name='conv1')(input)\n",
    "    x = PReLU(shared_axes=[1,2],name='PReLU1')(x)\n",
    "    x = MaxPool2D(pool_size=2)(x)\n",
    "    x = Conv2D(16, (3, 3), strides=1, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(shared_axes=[1,2],name='PReLU2')(x)\n",
    "    x = Conv2D(32, (3, 3), strides=1, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(shared_axes=[1,2],name='PReLU3')(x)\n",
    "    classifier = Conv2D(2, (1, 1), activation='softmax', name='conv4-1')(x)\n",
    "    bbox_regress = Conv2D(4, (1, 1), name='conv4-2')(x)\n",
    "    model = Model([input], [classifier, bbox_regress])\n",
    "    model.load_weights(weight_path, by_name=True)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_12net = create_Kao_Pnet()\n",
    "model_24net = create_Kao_Rnet()\n",
    "model_48net = create_Kao_Onet()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 24, 24, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 22, 22, 28)   784         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prelu1 (PReLU)                  (None, 22, 22, 28)   28          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 11, 11, 28)   0           prelu1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 9, 9, 48)     12144       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu2 (PReLU)                  (None, 9, 9, 48)     48          conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 4, 4, 48)     0           prelu2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 3, 3, 64)     12352       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu3 (PReLU)                  (None, 3, 3, 64)     64          conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 64, 3, 3)     0           prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 576)          0           permute_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Dense)                   (None, 128)          73856       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prelu4 (PReLU)                  (None, 128)          128         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5-1 (Dense)                 (None, 2)            258         prelu4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5-2 (Dense)                 (None, 4)            516         prelu4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 100,178\n",
      "Trainable params: 100,178\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "plot_model(model_12net, to_file='model_24net.png')\n",
    "model_24net.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the weights with kernel 2x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer_weights(src_model):\n",
    "    \n",
    "    for idx,layer in enumerate(src_model.layers):\n",
    "        if(layer.name == 'conv3'):\n",
    "            original_weights = layer.get_weights()[0]\n",
    "            original_biases = layer.get_weights()[1]\n",
    "    return original_weights, original_biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2, 48, 64)\n"
     ]
    }
   ],
   "source": [
    "original_weights, original_biases = transfer_weights(model_24net)\n",
    "\n",
    "print(original_weights.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padd them with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_padding(original_weights, VERBOSE=False):\n",
    "    # get the shape\n",
    "    f_w, f_h, f_d, f_num = original_weights.shape\n",
    "    \n",
    "    if(VERBOSE):\n",
    "        print(\"f_w: {}, f__h: {}, f_d: {}, f_num: {} \" .format(f_w, f_h, f_d, f_num))\n",
    "        print(\"\")\n",
    "        \n",
    "    # change te order, just for visualization\n",
    "    weights = np.transpose(original_weights, (3,2,1,0))\n",
    "    if(VERBOSE):\n",
    "        print(\"weights\")\n",
    "        print(weights)\n",
    "        print(\"\")\n",
    "\n",
    "    # create the 0 padding, forst for width, then for height \n",
    "    # draw on a paper to understand\n",
    "    zeros_width = np.zeros((f_num,f_d,1,f_w))\n",
    "    zeros_height = np.zeros((f_num,f_d,3,1))\n",
    "    \n",
    "    \n",
    "    weights_vertical_padded = np.concatenate((weights, zeros_width), axis=2)\n",
    "    weights_horizontal_padded = np.concatenate((weights_vertical_padded, zeros_height), axis=3)\n",
    "    \n",
    "    modified_weights = np.transpose(weights_horizontal_padded, (3,2,1,0))\n",
    "    \n",
    "    return modified_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "modified_weights = zero_padding(original_weights, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replace the layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_create_Kao_Rnet (weight_path = 'models/24net.h5'):\n",
    "    input = Input(shape=[24, 24, 3])  # change this shape to [None,None,3] to enable arbitraty shape input\n",
    "    x = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    classifier = Dense(2, activation='softmax', name='conv5-1')(x)\n",
    "    bbox_regress = Dense(4, name='conv5-2')(x)\n",
    "    \n",
    "    model = Model([input], [classifier, bbox_regress])\n",
    "    \n",
    "    ancient_weights = model.layers[1].get_weights()[0]\n",
    "    ancient_biases = model.layers[1].get_weights()[1]\n",
    "    \n",
    "    print(\"Before replacing the weights\")\n",
    "    print(\"ancient_weights.shape: \",ancient_weights.shape)\n",
    "    print(\"ancient_biases.shape: \",ancient_biases.shape)\n",
    "    print(\"\")\n",
    "    print(\"ancient_weights\")\n",
    "    print(ancient_weights)\n",
    "    print(\"\")\n",
    "    print(\"ancient_biases\")\n",
    "    print(ancient_biases)\n",
    "    print(\"\")\n",
    "    \n",
    "    # We generate some random weights to replace the original ones\n",
    "    weights = np.random.random((3,3,3,28))\n",
    "    biases = np.zeros((28,))\n",
    "    \n",
    "    # we add the weights and biases in one list\n",
    "    weights_biases = []\n",
    "    weights_biases.append(weights)\n",
    "    weights_biases.append(biases)\n",
    "    \n",
    "    # we replace\n",
    "    model.layers[1].set_weights(weights_biases)\n",
    "    \n",
    "    \n",
    "    print(\"After replacing the weights\")\n",
    "    new_weights = model.layers[1].get_weights()[0]\n",
    "    new_biases = model.layers[1].get_weights()[1]\n",
    "    \n",
    "    print(\"Before replacing the weights\")\n",
    "    print(\"new_weights.shape: \",new_weights.shape)\n",
    "    print(\"new_biases.shape: \",new_biases.shape)\n",
    "    print(\"\")\n",
    "    print(\"new_weights\")\n",
    "    print(new_weights)\n",
    "    print(\"\")\n",
    "    print(\"new_biases\")\n",
    "    print(new_biases)\n",
    "    print(\"\")\n",
    "    \n",
    "    #for idx,layer in enumerate(model.layers):\n",
    "        #if(layer.name == 'conv1'):\n",
    "            #model.layers[i].set_weights(weights) \n",
    "    \n",
    "    ''''\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu1')(x)\n",
    "    x = MaxPool2D(pool_size=3,strides=2, padding='same')(x)\n",
    "\n",
    "    x = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu2')(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    x = Conv2D(64, (2, 2), strides=1, padding='valid', name='conv3')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu3')(x)\n",
    "    x = Permute((3, 2, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "    \n",
    "    x = Dense(128, name='conv4')(x)\n",
    "    x = PReLU( name='prelu4')(x)\n",
    "    \n",
    "    classifier = Dense(2, activation='softmax', name='conv5-1')(x)\n",
    "    bbox_regress = Dense(4, name='conv5-2')(x)\n",
    "    \n",
    "    model = Model([input], [classifier, bbox_regress])\n",
    "    model.load_weights(weight_path, by_name=True)\n",
    "    \n",
    "    for idx,layer in enumerate(model.layers):\n",
    "        if(layer.name == 'conv3'):\n",
    "            original_weights = layer.get_weights()[0]\n",
    "            original_biases = layer.get_weights()[1]\n",
    "            \n",
    "            print(\"original_weights\")\n",
    "            print(original_weights)\n",
    "            \n",
    "            model.layer = []\n",
    "    '''       \n",
    "    return model\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before replacing the weights\n",
      "ancient_weights.shape:  (3, 3, 3, 28)\n",
      "ancient_biases.shape:  (28,)\n",
      "\n",
      "ancient_weights\n",
      "[[[[-0.11830183 -0.09517246  0.04857461 -0.0110741   0.07691772\n",
      "     0.14076607 -0.12253118  0.080798   -0.13324134 -0.1461177\n",
      "    -0.0518246  -0.03283762  0.06046167 -0.13052371  0.14115275\n",
      "    -0.10770708 -0.12819193  0.01363121  0.07848297 -0.12344369\n",
      "    -0.05095838  0.12184589  0.05023107 -0.07442015 -0.12363347\n",
      "     0.01260486 -0.08452534  0.07408376]\n",
      "   [ 0.01650062  0.09919231  0.03267221  0.08201979  0.06669044\n",
      "     0.13378306  0.06313889 -0.00488865 -0.00797246  0.14344917\n",
      "    -0.05811741 -0.04767305  0.02611342 -0.0950589  -0.07135057\n",
      "     0.08457288 -0.11147858  0.0958682  -0.09106248 -0.05096807\n",
      "     0.04389088  0.12800933  0.08854109  0.04459155 -0.0478272\n",
      "     0.06324185 -0.0440629   0.04159707]\n",
      "   [-0.00526845 -0.06792262  0.04748498  0.00567271 -0.04225403\n",
      "     0.14220242  0.13280828  0.09083578  0.075752   -0.03383044\n",
      "    -0.05322604 -0.14612927  0.08246882 -0.0153854   0.11807887\n",
      "    -0.09709639  0.13313134  0.11460249 -0.12610102 -0.09441963\n",
      "    -0.03685202  0.12418248 -0.10534097 -0.03656353  0.07416715\n",
      "     0.00467394 -0.05179901  0.08325557]]\n",
      "\n",
      "  [[-0.07537762 -0.0045087  -0.09200586  0.04899246 -0.08992218\n",
      "    -0.1413027   0.05442087 -0.01727995  0.07596053  0.07402636\n",
      "    -0.09950666  0.05310971 -0.09803295 -0.01894383 -0.1228063\n",
      "    -0.06795447  0.0273426  -0.00411974 -0.02662781 -0.0875216\n",
      "     0.02420117 -0.08763586  0.0760534  -0.12911287  0.11960243\n",
      "     0.10679717  0.09891516  0.12715499]\n",
      "   [ 0.12397318 -0.02481653 -0.05162489 -0.11211649  0.00328559\n",
      "     0.0348569   0.08438195  0.10363902  0.03372544 -0.0273449\n",
      "     0.12113313 -0.14590456 -0.00608411 -0.02206691  0.12391786\n",
      "     0.08452128 -0.00836086 -0.09680368 -0.05566103 -0.11108238\n",
      "    -0.12367469  0.11229838 -0.12231049 -0.11719111 -0.13209583\n",
      "    -0.03547582  0.03848957 -0.03419755]\n",
      "   [ 0.1305881   0.00374854  0.12090321  0.04241158 -0.1465698\n",
      "    -0.04335266  0.04343219  0.02939317  0.06052324  0.07929964\n",
      "    -0.13718426  0.13608761 -0.091971   -0.07649666  0.01331389\n",
      "    -0.02645575 -0.13867497  0.1050794   0.02093388 -0.0128009\n",
      "    -0.06759617 -0.11219753  0.07921471 -0.0251297   0.03596967\n",
      "     0.02465416 -0.0870325  -0.12574556]]\n",
      "\n",
      "  [[-0.14566432 -0.0951224  -0.08551687  0.08720143  0.01069708\n",
      "    -0.09037268  0.08381931  0.11494716 -0.01043329 -0.14033265\n",
      "    -0.06987323 -0.06653433  0.04910885 -0.08600076 -0.06191245\n",
      "     0.08640067 -0.02890886 -0.00473632 -0.12636772 -0.11402273\n",
      "     0.01733986  0.02105366 -0.11456452 -0.12647337 -0.02370337\n",
      "    -0.10862236  0.13023008  0.09185188]\n",
      "   [-0.09310672 -0.05499767  0.00941043  0.0055674   0.02293549\n",
      "    -0.09253629  0.14254232  0.0176798  -0.05365549  0.03102303\n",
      "     0.07433932 -0.13493015 -0.05003717  0.01548243 -0.14595613\n",
      "    -0.07624975  0.01803385  0.01429853 -0.1032846  -0.10872088\n",
      "     0.00458388 -0.03978985 -0.02779475  0.09525539  0.0733532\n",
      "     0.06597459  0.13140313  0.11503033]\n",
      "   [ 0.12472035 -0.06362254 -0.04194569 -0.03844386 -0.05727389\n",
      "    -0.11232312  0.12062041 -0.13754572  0.07755941  0.03471558\n",
      "     0.11444317  0.10178284 -0.01866043  0.04226473  0.14569251\n",
      "     0.1048242  -0.05551645  0.03557372  0.0367839  -0.05108746\n",
      "     0.02161577 -0.13486207  0.03282361 -0.00321415 -0.08773348\n",
      "    -0.11121531  0.06900869  0.03960052]]]\n",
      "\n",
      "\n",
      " [[[ 0.1196409   0.12809543  0.11382012 -0.05840072  0.0634715\n",
      "     0.00636764 -0.06169267  0.01269972  0.06205496 -0.09915738\n",
      "     0.00868036 -0.13188836  0.13916431 -0.09946775  0.09039563\n",
      "     0.13094471  0.01912029  0.10379086 -0.04939377 -0.06241921\n",
      "     0.05024754  0.10900132  0.13226868  0.05700058  0.00835481\n",
      "     0.12672736  0.03414463 -0.140963  ]\n",
      "   [-0.05648582  0.09335527  0.04240616  0.13720189 -0.1166216\n",
      "    -0.11065492 -0.03782476 -0.00202109 -0.05651291 -0.14331841\n",
      "     0.12529118 -0.12178251 -0.07753129 -0.07957166  0.02189356\n",
      "    -0.05298056 -0.08097257  0.02844094 -0.09348908 -0.10720193\n",
      "    -0.10558015  0.1224242  -0.11565447  0.10811408  0.11317281\n",
      "     0.07033701  0.04412489  0.09743434]\n",
      "   [-0.14008102  0.09626584 -0.02969074 -0.00841521 -0.07096402\n",
      "     0.04610673 -0.13215825 -0.12288082  0.10797672 -0.11968613\n",
      "    -0.04068106 -0.02115706  0.02616525  0.08884934  0.10607238\n",
      "    -0.07844832 -0.12088367  0.09198961  0.06939737 -0.07032178\n",
      "    -0.01283175 -0.04424069 -0.05566533  0.02525315 -0.037242\n",
      "    -0.02486236  0.0354981   0.10031949]]\n",
      "\n",
      "  [[-0.13324718 -0.01932882  0.05701397  0.00104034 -0.10489124\n",
      "    -0.06453481 -0.05994754 -0.02772765 -0.10158237 -0.06965649\n",
      "    -0.10625904  0.05343246 -0.0842914   0.00706805 -0.02180345\n",
      "     0.094923    0.02998485  0.00358543 -0.03923512 -0.03064304\n",
      "     0.13104688  0.14258413  0.09949879 -0.12613283  0.12063806\n",
      "    -0.04859936 -0.08669712 -0.10545526]\n",
      "   [ 0.10249908 -0.00837663 -0.07301755  0.07648981 -0.07301874\n",
      "    -0.02562873  0.01141933  0.14026748 -0.08519559 -0.12637621\n",
      "    -0.00061637  0.11045937 -0.02299266  0.12042786 -0.04660194\n",
      "    -0.08860029  0.04965292  0.11778252 -0.02855404  0.03928071\n",
      "     0.07961021 -0.00066686  0.1119063  -0.07540643  0.11242439\n",
      "     0.12206249 -0.14169745  0.12939768]\n",
      "   [ 0.03163065 -0.1004089   0.1370338   0.00780398  0.05976325\n",
      "    -0.02494897  0.12525667  0.0007799  -0.11620389 -0.05019327\n",
      "    -0.13650948  0.11185275 -0.12933356 -0.02161217  0.05749713\n",
      "     0.1018369  -0.07570418  0.12351646  0.05394866 -0.11627654\n",
      "    -0.1443576   0.0099065   0.05533077  0.06019683 -0.05928173\n",
      "     0.03205325 -0.10112882  0.14012839]]\n",
      "\n",
      "  [[ 0.11966078  0.12051402 -0.07352582 -0.09469742 -0.0527455\n",
      "    -0.11357391  0.06424622 -0.00438561 -0.08642007 -0.10725679\n",
      "    -0.12025933  0.01208101  0.07725714 -0.0456387   0.0564706\n",
      "     0.08448964 -0.02416841 -0.14462031 -0.00822923  0.00497565\n",
      "    -0.12328817 -0.1252649   0.13273315  0.11607085  0.09576043\n",
      "     0.13685448 -0.08244428  0.07339828]\n",
      "   [-0.04812156 -0.04319175  0.10191593  0.00960363 -0.0160592\n",
      "    -0.06471581  0.10354368  0.00425833 -0.08615083  0.12753417\n",
      "    -0.03971894  0.13493238  0.00018576 -0.11725454 -0.00967336\n",
      "    -0.02718701 -0.01925504 -0.10355256  0.04099905 -0.04745648\n",
      "     0.08486253  0.05808084 -0.14026706 -0.12736917 -0.04123069\n",
      "    -0.01138736  0.02084909  0.08607407]\n",
      "   [-0.1061016   0.0899197   0.03325652 -0.07535944 -0.0743455\n",
      "    -0.01390935  0.03367405 -0.04183598  0.00399625  0.13939847\n",
      "     0.11802889  0.08461027  0.0369733  -0.07058256 -0.09144316\n",
      "    -0.04836564 -0.08153572  0.04176766  0.13724066  0.13266481\n",
      "     0.02630541 -0.04368771 -0.01261543 -0.02135845 -0.03235338\n",
      "     0.11152701 -0.05285095  0.02710725]]]\n",
      "\n",
      "\n",
      " [[[ 0.02749462 -0.01822449  0.12776484 -0.11953118 -0.04178192\n",
      "    -0.13698645  0.03603429  0.07930736  0.0912068  -0.04185724\n",
      "    -0.08053234  0.08358164 -0.07694237  0.05658357  0.11094983\n",
      "     0.08150621  0.0266297   0.08878657  0.015856    0.08976264\n",
      "     0.05445744 -0.06779853 -0.12433732 -0.12023118 -0.03377548\n",
      "     0.10590474 -0.03280007 -0.0523008 ]\n",
      "   [-0.13528442  0.1018361   0.0084168  -0.10362427 -0.0469364\n",
      "     0.11592101 -0.0373214  -0.14030237  0.03962524 -0.11228453\n",
      "     0.11700378 -0.09856409 -0.02885336  0.04566541  0.1232173\n",
      "    -0.04105636 -0.11669708  0.11821802 -0.02866019  0.12639518\n",
      "     0.03307502 -0.12755679 -0.08563438  0.08478008  0.09922168\n",
      "    -0.14204533  0.07424337  0.07583001]\n",
      "   [ 0.04177231 -0.09753207 -0.11335818 -0.00986953  0.08608967\n",
      "     0.02483715  0.04610325 -0.13658059  0.1250285   0.09974571\n",
      "    -0.14496757  0.13868667 -0.13812059  0.06565042  0.01969218\n",
      "     0.09909438  0.06735751  0.08682992 -0.12970252  0.04801939\n",
      "     0.10614981  0.08231659 -0.11470634 -0.00419739 -0.08470543\n",
      "    -0.06182899 -0.14263782  0.04427408]]\n",
      "\n",
      "  [[-0.08401043  0.01672632 -0.13325645 -0.1245628   0.01917644\n",
      "     0.00319016 -0.00171405  0.06618203  0.12703328 -0.07591448\n",
      "    -0.08094509  0.12812124 -0.04171413 -0.09467937  0.05095586\n",
      "    -0.06097546 -0.09961903 -0.06065936  0.05655707 -0.01542717\n",
      "    -0.0809196  -0.06869747  0.13175403 -0.14079368  0.11430563\n",
      "    -0.0609068   0.10387932 -0.07614038]\n",
      "   [-0.09833707  0.02845968  0.01308323 -0.07936443 -0.14617357\n",
      "    -0.05274099 -0.09363341  0.05940753  0.1282747  -0.03300016\n",
      "    -0.1411239  -0.12099307  0.07016161  0.02048558  0.02614598\n",
      "     0.00135836 -0.14636894 -0.07333048  0.07452857 -0.09272331\n",
      "     0.07787894 -0.13920435 -0.1161626   0.04193261 -0.07946589\n",
      "     0.01170693  0.0319161  -0.04813501]\n",
      "   [-0.00988472  0.00888805  0.04097129  0.05993743 -0.02036464\n",
      "    -0.11298501  0.1447001   0.03831726  0.09728187 -0.04575688\n",
      "     0.09407559 -0.04519928 -0.12673181 -0.113177    0.02001578\n",
      "    -0.01648755 -0.04756001 -0.12314905  0.00165926  0.00241101\n",
      "     0.02795614 -0.13227828 -0.02478562 -0.14616017  0.03634885\n",
      "     0.14207785 -0.10352197  0.09051237]]\n",
      "\n",
      "  [[ 0.13643475 -0.01188619 -0.10268334 -0.10179306 -0.10512406\n",
      "    -0.05704606  0.1414193  -0.01341867  0.07320395  0.06228051\n",
      "    -0.10182071  0.12883215 -0.05800417  0.0923318  -0.05049176\n",
      "    -0.14198034  0.07243402 -0.13570148  0.07251801  0.12843485\n",
      "     0.02418473  0.08333987  0.01595114  0.02225965 -0.08409312\n",
      "    -0.04142778 -0.08545873 -0.05257201]\n",
      "   [-0.11559472  0.13411488 -0.00224842 -0.01032259  0.05936494\n",
      "    -0.14186604  0.03181602  0.0798028  -0.09676326 -0.12945445\n",
      "     0.06829365 -0.04006948  0.04701349 -0.07941446 -0.05630023\n",
      "     0.07301521 -0.00943348  0.0694765  -0.02955005 -0.00052847\n",
      "     0.06693676  0.06426311  0.08610362 -0.139335    0.14654644\n",
      "     0.06676939 -0.00185974 -0.0261636 ]\n",
      "   [-0.02254527  0.07868816  0.08020726  0.03982671  0.03024715\n",
      "    -0.027813    0.08193861 -0.03272158 -0.04756308 -0.13148311\n",
      "    -0.01707321 -0.05911031 -0.139828    0.09238262 -0.1212168\n",
      "     0.00245894  0.10081492 -0.0474275   0.10264197 -0.05727515\n",
      "     0.1042711   0.13290875 -0.10987248 -0.0728334  -0.00741281\n",
      "     0.13214429  0.01547067  0.13399218]]]]\n",
      "\n",
      "ancient_biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "\n",
      "After replacing the weights\n",
      "Before replacing the weights\n",
      "new_weights.shape:  (3, 3, 3, 28)\n",
      "new_biases.shape:  (28,)\n",
      "\n",
      "new_weights\n",
      "[[[[0.5419471  0.9678547  0.40169826 0.64448303 0.09364226 0.59186494\n",
      "    0.27758992 0.6892857  0.1444455  0.295867   0.82804567 0.11695204\n",
      "    0.25488672 0.6645606  0.41413108 0.16480567 0.59608126 0.5699302\n",
      "    0.8844315  0.26614055 0.57607025 0.4129587  0.17759536 0.9236615\n",
      "    0.41507676 0.0550211  0.58416915 0.57988083]\n",
      "   [0.447018   0.26196143 0.6180634  0.7680647  0.34029096 0.39682293\n",
      "    0.9817085  0.03140421 0.4047056  0.38790613 0.9851788  0.76358485\n",
      "    0.4555062  0.34048527 0.41663066 0.48984313 0.14061166 0.57439524\n",
      "    0.65765435 0.04299692 0.5560672  0.7768273  0.29353786 0.5558569\n",
      "    0.34798697 0.67230743 0.34031692 0.58487135]\n",
      "   [0.5319242  0.48071694 0.09201103 0.4054461  0.13475648 0.66729295\n",
      "    0.03156495 0.6228689  0.69217855 0.51964396 0.6549054  0.36467305\n",
      "    0.11535241 0.6246282  0.09467724 0.2012272  0.3476282  0.91480047\n",
      "    0.5133887  0.4674008  0.7332089  0.7496277  0.14781408 0.7990232\n",
      "    0.24909304 0.9025457  0.3625871  0.31360266]]\n",
      "\n",
      "  [[0.967556   0.07623649 0.5319072  0.6894515  0.6930824  0.05006767\n",
      "    0.26952    0.8548281  0.7965813  0.4644381  0.93450385 0.8394014\n",
      "    0.87923324 0.21924306 0.21147187 0.7652999  0.248345   0.14263463\n",
      "    0.671362   0.84947646 0.9684956  0.04225044 0.1943694  0.2418777\n",
      "    0.9006137  0.19348294 0.83874786 0.46201363]\n",
      "   [0.4928746  0.01319259 0.6614482  0.05438503 0.73847836 0.9910727\n",
      "    0.30676094 0.72227246 0.8684952  0.39049602 0.95455456 0.52037644\n",
      "    0.4631266  0.04734157 0.8485514  0.5391209  0.16580181 0.7085356\n",
      "    0.6520275  0.9543417  0.14781883 0.7229366  0.7999917  0.02775838\n",
      "    0.16581455 0.9795576  0.2667584  0.45494834]\n",
      "   [0.69822395 0.38539428 0.7731289  0.4113279  0.7958755  0.6604933\n",
      "    0.1555754  0.08278044 0.51506823 0.5020921  0.21793525 0.43580347\n",
      "    0.38613585 0.6608964  0.5244583  0.8058761  0.51502776 0.4101009\n",
      "    0.6719935  0.49391258 0.6980928  0.92391425 0.56675446 0.84104985\n",
      "    0.18952392 0.17921355 0.7571119  0.8531972 ]]\n",
      "\n",
      "  [[0.45196304 0.27046913 0.15465565 0.3130025  0.02018188 0.42368478\n",
      "    0.54164493 0.28749567 0.8616502  0.13534477 0.08181697 0.8907944\n",
      "    0.49050277 0.08804257 0.43971667 0.16307737 0.54605925 0.9040409\n",
      "    0.9361382  0.47793633 0.6031015  0.18343166 0.78110164 0.9200004\n",
      "    0.64213294 0.3723458  0.8917892  0.6678209 ]\n",
      "   [0.45118415 0.65551484 0.70162195 0.19964124 0.18994752 0.80500233\n",
      "    0.62117624 0.9764682  0.21088162 0.05190996 0.5532868  0.8835757\n",
      "    0.02015113 0.34637892 0.51141775 0.69430023 0.01116062 0.09817909\n",
      "    0.1390449  0.83160543 0.6035066  0.82150435 0.15594506 0.8874808\n",
      "    0.7340046  0.79764205 0.5740209  0.9510957 ]\n",
      "   [0.43602628 0.07215259 0.64149916 0.8656271  0.07512373 0.0597925\n",
      "    0.19637772 0.05680443 0.7773483  0.9435178  0.03270547 0.4592474\n",
      "    0.07414456 0.7315947  0.9504286  0.08763663 0.10132252 0.01467114\n",
      "    0.3657463  0.7684471  0.29180846 0.35826668 0.13323203 0.7330286\n",
      "    0.74207133 0.84243906 0.51596916 0.70123535]]]\n",
      "\n",
      "\n",
      " [[[0.29874095 0.47783896 0.10207567 0.9677191  0.06053752 0.45954618\n",
      "    0.24091296 0.8801498  0.90707344 0.9392583  0.9533683  0.30797827\n",
      "    0.38912123 0.11445019 0.7455894  0.8544622  0.41985327 0.16911712\n",
      "    0.19976969 0.24017504 0.23992991 0.49673682 0.50218993 0.9286557\n",
      "    0.05259214 0.76285106 0.8562733  0.23397449]\n",
      "   [0.49713176 0.7836167  0.5685013  0.05193941 0.92216057 0.9831183\n",
      "    0.22612537 0.0146878  0.54600626 0.64006126 0.46998748 0.22706933\n",
      "    0.47404498 0.41130063 0.7292465  0.40725842 0.5760583  0.7852419\n",
      "    0.2277488  0.45614174 0.461578   0.76557744 0.58749205 0.32883447\n",
      "    0.70868057 0.14950038 0.1800237  0.26324993]\n",
      "   [0.81382924 0.45399237 0.3227984  0.4596993  0.2717029  0.16778804\n",
      "    0.04704122 0.13071044 0.78589106 0.97455406 0.32181132 0.01654822\n",
      "    0.0300619  0.3739318  0.05910558 0.98739725 0.40775067 0.26155907\n",
      "    0.05046215 0.7143569  0.43423572 0.80163676 0.2917063  0.98975164\n",
      "    0.12568687 0.4239832  0.2656086  0.00476067]]\n",
      "\n",
      "  [[0.39011455 0.7649001  0.66493565 0.06790119 0.5225173  0.66734856\n",
      "    0.47822788 0.5633966  0.53020847 0.36229786 0.25052038 0.4380874\n",
      "    0.6767992  0.50840396 0.2970807  0.7504802  0.21910581 0.9601366\n",
      "    0.7797611  0.13207923 0.63056535 0.23278165 0.20359617 0.53336155\n",
      "    0.37590286 0.8506625  0.2055858  0.1829774 ]\n",
      "   [0.2443286  0.50653636 0.44562644 0.5396465  0.19713059 0.6870444\n",
      "    0.3305435  0.96196634 0.04444741 0.67831516 0.7857212  0.07456696\n",
      "    0.27450123 0.4592046  0.40186366 0.8055941  0.8746545  0.30788007\n",
      "    0.86342543 0.47665274 0.6186411  0.91559625 0.39002883 0.91313934\n",
      "    0.00844514 0.46685663 0.9632781  0.9472951 ]\n",
      "   [0.25796142 0.8404874  0.41005585 0.7546406  0.00139365 0.15294097\n",
      "    0.6067694  0.8584839  0.74452984 0.58865184 0.33458322 0.6814476\n",
      "    0.5285891  0.02386007 0.79378307 0.09661624 0.53254104 0.25172612\n",
      "    0.68370533 0.14866872 0.61245775 0.5594334  0.33326223 0.39514783\n",
      "    0.7772115  0.68837845 0.640143   0.02247498]]\n",
      "\n",
      "  [[0.05435292 0.95549285 0.4879443  0.2959173  0.15672113 0.7561004\n",
      "    0.5115088  0.12239388 0.22184965 0.76331383 0.36665064 0.24014199\n",
      "    0.14097379 0.5651631  0.89135194 0.69710064 0.28889194 0.7862485\n",
      "    0.03461668 0.1168282  0.40466416 0.8771751  0.04526194 0.9517931\n",
      "    0.05225972 0.02232703 0.7807239  0.5043578 ]\n",
      "   [0.86702543 0.8281302  0.6161082  0.71379983 0.962122   0.22213215\n",
      "    0.37410048 0.69476485 0.5846065  0.09996812 0.8558529  0.7329008\n",
      "    0.3116992  0.8180462  0.34142953 0.05631557 0.14306626 0.19227788\n",
      "    0.49151027 0.32923973 0.70169216 0.7199453  0.43050605 0.792654\n",
      "    0.89183694 0.7117671  0.36128077 0.49990484]\n",
      "   [0.7897561  0.33132136 0.21979782 0.18755172 0.1766015  0.48704293\n",
      "    0.9311649  0.23037025 0.46206442 0.2246878  0.47793135 0.9844453\n",
      "    0.8151368  0.03014779 0.2926296  0.01862706 0.00526096 0.65256447\n",
      "    0.04910386 0.01143119 0.07618655 0.8601946  0.93200344 0.20002183\n",
      "    0.62166804 0.75749344 0.6683826  0.43391567]]]\n",
      "\n",
      "\n",
      " [[[0.5356971  0.9490998  0.48262107 0.54962206 0.11401653 0.582716\n",
      "    0.65757275 0.04588546 0.67128164 0.81597847 0.8048841  0.33376667\n",
      "    0.70256704 0.69337696 0.73822385 0.02084671 0.73424476 0.46328893\n",
      "    0.47468448 0.5049805  0.34154972 0.68898034 0.18964465 0.37287447\n",
      "    0.12895846 0.26548216 0.8403578  0.4640244 ]\n",
      "   [0.25416872 0.9119042  0.3812394  0.78096354 0.13408151 0.7397151\n",
      "    0.24994703 0.6538804  0.23650555 0.23166625 0.9697098  0.29945698\n",
      "    0.1567335  0.19430602 0.37749797 0.99733084 0.7477304  0.38503268\n",
      "    0.68499064 0.03567024 0.06325683 0.7672577  0.21294323 0.14784494\n",
      "    0.5336171  0.5084592  0.5975405  0.6230137 ]\n",
      "   [0.811193   0.7565908  0.7443604  0.20356402 0.4308798  0.3082865\n",
      "    0.58411026 0.73798084 0.30658916 0.0673686  0.10812742 0.28496194\n",
      "    0.67394423 0.7654089  0.16060737 0.36403716 0.22185293 0.17462027\n",
      "    0.84374565 0.6603817  0.08627044 0.84143347 0.8899972  0.26344204\n",
      "    0.993852   0.38956687 0.4240551  0.1843196 ]]\n",
      "\n",
      "  [[0.38056773 0.791252   0.82658243 0.733862   0.8608708  0.49207875\n",
      "    0.43145803 0.7541465  0.9318558  0.21158926 0.18888403 0.2555137\n",
      "    0.45143566 0.01116361 0.6743084  0.02153878 0.97322357 0.40507588\n",
      "    0.17315024 0.27271184 0.12254256 0.17606325 0.8657218  0.18324918\n",
      "    0.7665721  0.31656775 0.7606412  0.9402122 ]\n",
      "   [0.06610047 0.3642553  0.87659293 0.99563193 0.5288856  0.90061283\n",
      "    0.45354372 0.12223188 0.5726598  0.73980886 0.1279884  0.7850797\n",
      "    0.5988484  0.8862934  0.39051384 0.9369709  0.5755567  0.82768166\n",
      "    0.5309615  0.87140024 0.24023327 0.20618713 0.59176624 0.8510961\n",
      "    0.00897326 0.29910854 0.7971375  0.17545962]\n",
      "   [0.9846524  0.60308635 0.3894147  0.3769741  0.06207917 0.5121207\n",
      "    0.17879409 0.5702574  0.13588487 0.41946492 0.42461807 0.38898438\n",
      "    0.12458783 0.7343852  0.19399999 0.160915   0.03481791 0.53007627\n",
      "    0.49189034 0.906356   0.45548618 0.27727723 0.35337722 0.2633762\n",
      "    0.83656126 0.6192245  0.27155188 0.6002699 ]]\n",
      "\n",
      "  [[0.5295581  0.614796   0.05814144 0.6869702  0.7766626  0.3413115\n",
      "    0.11920028 0.3500411  0.04901101 0.6288793  0.76083374 0.46328196\n",
      "    0.7990348  0.21401438 0.57138383 0.9030198  0.9580213  0.20874843\n",
      "    0.5263002  0.91181123 0.5175098  0.42656627 0.66621107 0.2963057\n",
      "    0.14411084 0.4914877  0.19596869 0.7309815 ]\n",
      "   [0.55419147 0.6578157  0.32815835 0.9252681  0.8233198  0.8183087\n",
      "    0.7225774  0.29807222 0.7404669  0.40739435 0.098365   0.83668274\n",
      "    0.32992494 0.9552461  0.38852924 0.5777989  0.37299085 0.32620218\n",
      "    0.3636854  0.71956235 0.90928566 0.05381063 0.4212155  0.1425185\n",
      "    0.26412126 0.10277847 0.9496512  0.7435708 ]\n",
      "   [0.46635133 0.79119176 0.08289975 0.97165096 0.5171696  0.5938783\n",
      "    0.5834488  0.8600438  0.44833446 0.07469469 0.53931195 0.9181506\n",
      "    0.54118896 0.5382284  0.40596837 0.34488878 0.8206902  0.57902926\n",
      "    0.6990138  0.52828556 0.32837877 0.40356982 0.8784612  0.4724038\n",
      "    0.107999   0.77874225 0.12470779 0.22461295]]]]\n",
      "\n",
      "new_biases\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0.]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "new_model_24net = new_create_Kao_Rnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_A_New_Kao_Rnet():\n",
    "    input = Input(shape=[24, 24, 3])  # change this shape to [None,None,3] to enable arbitraty shape input\n",
    "    x = Conv2D(28, (3, 3), strides=1, padding='valid', name='conv1')(input)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu1')(x)\n",
    "    x = MaxPool2D(pool_size=3,strides=2, padding='same')(x)\n",
    "\n",
    "    x = Conv2D(48, (3, 3), strides=1, padding='valid', name='conv2')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu2')(x)\n",
    "    x = MaxPool2D(pool_size=3, strides=2)(x)\n",
    "\n",
    "    # changed padding to same\n",
    "    x = Conv2D(64, (3, 3), strides=1, padding='same', name='conv3')(x)\n",
    "    x = PReLU(shared_axes=[1, 2], name='prelu3')(x)\n",
    "    # my idea is to use a maxpool\n",
    "    x = MaxPool2D(pool_size=2, strides=1, name='gaga')(x)\n",
    "    x = Permute((3, 2, 1))(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(128, name='conv4')(x)\n",
    "    x = PReLU( name='prelu4')(x)\n",
    "    classifier = Dense(2, activation='softmax', name='conv5-1')(x)\n",
    "    bbox_regress = Dense(4, name='conv5-2')(x)\n",
    "    model = Model([input], [classifier, bbox_regress])\n",
    "    print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 24, 24, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 22, 22, 28)   784         input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "prelu1 (PReLU)                  (None, 22, 22, 28)   28          conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 11, 11, 28)   0           prelu1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 9, 9, 48)     12144       max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu2 (PReLU)                  (None, 9, 9, 48)     48          conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 4, 4, 48)     0           prelu2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (Conv2D)                  (None, 4, 4, 64)     27712       max_pooling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "prelu3 (PReLU)                  (None, 4, 4, 64)     64          conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gaga (MaxPooling2D)             (None, 3, 3, 64)     0           prelu3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "permute_3 (Permute)             (None, 64, 3, 3)     0           gaga[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 576)          0           permute_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4 (Dense)                   (None, 128)          73856       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "prelu4 (PReLU)                  (None, 128)          128         conv4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv5-1 (Dense)                 (None, 2)            258         prelu4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv5-2 (Dense)                 (None, 4)            516         prelu4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 115,538\n",
      "Trainable params: 115,538\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "create_A_New_Kao_Rnet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

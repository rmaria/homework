{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T11:16:48.514950Z",
     "start_time": "2018-07-01T11:16:48.509667Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "from datetime import date\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.689440Z",
     "start_time": "2018-07-01T10:47:25.047027Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../data/boxer dc kzn/april 2018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.720569Z",
     "start_time": "2018-07-01T10:47:25.690945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.803718Z",
     "start_time": "2018-07-01T10:47:25.722014Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.817030Z",
     "start_time": "2018-07-01T10:47:25.805055Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#drop all unnamed columns\n",
    "print('Initial cols',list(test_df.columns.values))\n",
    "print(\"\")\n",
    "unnamed_col_idxs = [idx for idx,col in enumerate(list(test_df.columns.values)) if \"Unnamed\" in col]\n",
    "print('Unnamed cols indexes',unnamed_col_idxs)\n",
    "print(\"\")\n",
    "test_df.drop(labels=test_df.columns[unnamed_col_idxs], axis='columns', inplace=True)\n",
    "print('removed Unnamed cols',list(test_df.columns.values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.832914Z",
     "start_time": "2018-07-01T10:47:25.818670Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df['LogOffReason'] = '/'+test_df['LogOffReason']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.842440Z",
     "start_time": "2018-07-01T10:47:25.834274Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['LogOffReason']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:25.876263Z",
     "start_time": "2018-07-01T10:47:25.844432Z"
    }
   },
   "outputs": [],
   "source": [
    "def column_to_flags(df, col, delimiter):\n",
    "    # split col column into separate True/False columns for each found flag delimited by delimiter\n",
    "    # assumes the entries in col are strings containing flags delimited by delimiter\n",
    "    # e.g.: \"flag0;flag1;flag2\" (delimiter is ;)\n",
    "    \n",
    "    # preprocess column by :\n",
    "    # converting nan to string\n",
    "    df[col] = df[col].fillna('')\n",
    "    #adding delimiter to start of entry, to support flags that are substrings of other flags\n",
    "    df[col] = delimiter + df[col] \n",
    "    \n",
    "    flags_strings = []\n",
    "    #1) find all possible flags\n",
    "    #1.1) extract each flag separated by delimiter from entries in col column\n",
    "    for entry_str in df[col]:\n",
    "        flags_strings += entry_str.split(delimiter)\n",
    "    #1.2) get rid of redundand flags by making the list a set\n",
    "    flags_set = set(flags_strings)\n",
    "    flags_set.remove('') # remove empty entry    \n",
    "    #1.3) convert to sorted list\n",
    "    flags_list = sorted(list(flags_set))\n",
    "    print('Converted ', col ,' column into flags',flags_list)\n",
    "    #1.4) add \n",
    "    #1.5) add each flag as a new column and mark entry with True\n",
    "    for flag_str in flags_list:\n",
    "        df[flag_str] = [delimiter+flag_str+delimiter in entry_str for entry_str in df[col]]\n",
    "    #1.6) remove original column\n",
    "    df.drop(labels=col, axis='columns', inplace=True )    \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:26.163993Z",
     "start_time": "2018-07-01T10:47:25.877710Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = column_to_flags(df=test_df, col=\"LogOffReason\", delimiter=\"/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:26.503396Z",
     "start_time": "2018-07-01T10:47:26.165550Z"
    }
   },
   "outputs": [],
   "source": [
    "df = column_to_flags(df=df, col=\"Result\", delimiter=\"/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Per driver stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:31.104127Z",
     "start_time": "2018-07-01T10:47:31.098584Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "bymachine = test_df.groupby('Driver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T10:47:31.968314Z",
     "start_time": "2018-07-01T10:47:31.923649Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# this value counts in fact orders the list by driver, from lowest to highest number or letter\n",
    "bymachine['Harsh Acceleration'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Per machine stats  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### explore date & time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:28:18.968638Z",
     "start_time": "2018-07-01T14:28:18.962188Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[\"Date & Time\"][:5]\n",
    "\n",
    "# Observe the problems with the date, where we have 2018/04/3011:45:47PM instead of 2018/04/30 11:45:47 PM\n",
    "# so we split in the first 10 and the last 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Date & Time into Data and Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T11:07:38.580429Z",
     "start_time": "2018-07-01T11:07:38.533758Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_date = lambda x: x[:10]\n",
    "extract_time = lambda x: x[10:]\n",
    "df['Date'] = df['Date & Time'].map(extract_date)\n",
    "df['Time'] = df['Date & Time'].map(extract_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:28:48.263578Z",
     "start_time": "2018-07-01T14:28:48.237364Z"
    }
   },
   "outputs": [],
   "source": [
    "# since we have a missing space sometimes, we check for the space\n",
    "separate_date_time = lambda x: x[:10]+' '+x[10:] if x[10] != ' ' else x \n",
    "df[\"Date & Time\"] = df[\"Date & Time\"].map(separate_date_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:28:55.382714Z",
     "start_time": "2018-07-01T14:28:55.374272Z"
    }
   },
   "outputs": [],
   "source": [
    "df[\"Date & Time\"][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T11:07:39.201369Z",
     "start_time": "2018-07-01T11:07:39.190828Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df['Date'].head())\n",
    "print(df['Time'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:29:36.983918Z",
     "start_time": "2018-07-01T14:29:36.965605Z"
    }
   },
   "outputs": [],
   "source": [
    "# from fastai library:\n",
    "# https://github.com/fastai/fastai/blob/master/fastai/structured.py\n",
    "def add_datepart(df, fldname, drop=True, time=False):\n",
    "    \"\"\"add_datepart converts a column of df from a datetime64 to many columns containing\n",
    "    the information from the date. This applies changes inplace.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df: A pandas data frame. df gain several new columns.\n",
    "    fldname: A string that is the name of the date column you wish to expand.\n",
    "        If it is not a datetime64 series, it will be converted to one with pd.to_datetime.\n",
    "    drop: If true then the original date column will be removed.\n",
    "    time: If true time features: Hour, Minute, Second will be added.\n",
    "    Examples:\n",
    "    ---------\n",
    "    >>> df = pd.DataFrame({ 'A' : pd.to_datetime(['3/11/2000', '3/12/2000', '3/13/2000'], infer_datetime_format=False) })\n",
    "    >>> df\n",
    "        A\n",
    "    0   2000-03-11\n",
    "    1   2000-03-12\n",
    "    2   2000-03-13\n",
    "    >>> add_datepart(df, 'A')\n",
    "    >>> df\n",
    "        AYear AMonth AWeek ADay ADayofweek ADayofyear AIs_month_end AIs_month_start AIs_quarter_end AIs_quarter_start AIs_year_end AIs_year_start AElapsed\n",
    "    0   2000  3      10    11   5          71         False         False           False           False             False        False          952732800\n",
    "    1   2000  3      10    12   6          72         False         False           False           False             False        False          952819200\n",
    "    2   2000  3      11    13   0          73         False         False           False           False             False        False          952905600\n",
    "    \"\"\"\n",
    "    fld = df[fldname]\n",
    "    fld_dtype = fld.dtype\n",
    "    if isinstance(fld_dtype, pd.core.dtypes.dtypes.DatetimeTZDtype):\n",
    "        fld_dtype = np.datetime64\n",
    "\n",
    "    if not np.issubdtype(fld_dtype, np.datetime64):\n",
    "        df[fldname] = fld = pd.to_datetime(fld, infer_datetime_format=True)\n",
    "    targ_pre = re.sub('[Dd]ate$', '', fldname)\n",
    "    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear',\n",
    "            'Is_month_end', 'Is_month_start', 'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']\n",
    "    if time: attr = attr + ['Hour', 'Minute', 'Second']\n",
    "    for n in attr: df[targ_pre +'_' + n] = getattr(fld.dt, n.lower())\n",
    "    df[targ_pre + 'Elapsed'] = fld.astype(np.int64) // 10 ** 9\n",
    "    if drop: df.drop(fldname, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:30:30.185181Z",
     "start_time": "2018-07-01T14:30:20.800430Z"
    }
   },
   "outputs": [],
   "source": [
    "add_datepart(df,'Date & Time',drop=False,time=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:31:40.178037Z",
     "start_time": "2018-07-01T14:31:40.173390Z"
    }
   },
   "outputs": [],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove spaces and & from names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.strip().str.replace(' ', '_')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversed dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T11:24:24.902222Z",
     "start_time": "2018-07-01T11:24:24.898238Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reverse_dataframe(df):\n",
    "    df_index_col = df.index\n",
    "    reversed_df = df.iloc[::-1]\n",
    "    reversed_df.index = df_index_col\n",
    "    reversed_df.to_csv(\"reversed_df.csv\")\n",
    "    return reversed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reversed_df = reverse_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If the driver shift is between 2 months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_line_df(df):\n",
    "    # if the first line does not contain Not Logged On or Driver change\n",
    "    if(df.Driver[0] != 'Not Logged On' and df.Driver_Change[0] != True):\n",
    "        df = pd.concat([df[:1], df], ignore_index=True)\n",
    "        df.iloc[0, df.columns.get_loc('Driver')] = 'Not Logged On'\n",
    "        df.iloc[0, df.columns.get_loc('Driver_Change')] = True\n",
    "        # save\n",
    "        df.to_csv(\"iverse_modif_df.csv\")\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = add_line_df(reversed_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:10:19.555131Z",
     "start_time": "2018-07-01T14:10:19.548004Z"
    }
   },
   "source": [
    "# Get total driving time / driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T14:19:36.128039Z",
     "start_time": "2018-07-01T14:19:36.110252Z"
    },
    "scrolled": true
   },
   "source": [
    "#### from the \"Ignition on = True\" after \"Logged on\" until \"Ignition on = False\" before \"Logged off\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Get the ! values of driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the fields in Driver\n",
    "print(new_df.Driver.values)\n",
    "# get how many ! drivers are\n",
    "count_unique_drivers = len(new_df.Driver.unique()) - 1\n",
    "print(\"cout ! values: \",count_unique_drivers)\n",
    "unique_drivers = new_df.Driver.unique()\n",
    "print(\"unique_drivers: \",unique_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) (b) remove Not Logged On tag from unique_drivers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of 'Not Logged On' element\n",
    "index_nlo = np.where(unique_drivers=='Not Logged On')[0][0]\n",
    "print(\"index_nlo: \",index_nlo)\n",
    "unique_drivers = np.delete(unique_drivers, index_nlo)\n",
    "print(\"unique drivers: \",unique_drivers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) get teh indexes of \"Not Logged On\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the index of Driver Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for idx, val in small_df.Driver_Change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = [idx for idx,col in enumerate(new_df.Driver.values) if col=='Not Logged On']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the driver logged on before this driver change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_time_logged_on(df, indexes):\n",
    "    # am index si indexul indexului\n",
    "    for i, ind in enumerate(indexes):\n",
    "        if(df.iloc[ind+1]['Driver'] != 'Not Logged On') and ind !=indexes[-1]:\n",
    "            #print(\"i = {} and ind = {} \".format(i,ind))\n",
    "            #print(\"ind+1 = \",ind+1)\n",
    "            #print(\"indexes[i+1]-1 = \",indexes[i+1]-1)\n",
    "            #print(\"i= {} and index={} \".format(i,ind))\n",
    "            print(\"Driver: \",df.iloc[ind+1]['Driver'])\n",
    "            print(\"Log on time: \",df.iloc[ind+1]['Date_&_Time'])\n",
    "            print( \"Log off time: \",df.iloc[indexes[i+1]]['Date_&_Time'])                                   \n",
    "    \n",
    "        elif(ind ==indexes[-1]):\n",
    "            get_the_last_index_of_df = df.index[-1]\n",
    "            print(\"Driver: \",df.iloc[ind+1]['Driver'])\n",
    "            print(\"Log on time: \",df.iloc[ind+1]['Date_&_Time'])\n",
    "            print( \"Log off time: \",df.iloc[get_the_last_index_of_df]['Date_&_Time'])   \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#small_df = new_df[:66]\n",
    "get_time_logged_on(new_df, indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
